#!/usr/bin/env python3
"""
AI Feedback Generator for TestRail Results
Generates intelligent insights using LLM based on test execution results
with QA Lead perspective: Risk Analysis, User Impact, and Business Context
"""

from typing import List, Optional
from .state import TestResult
from .nodes import get_llm
import os


class AIFeedbackGenerator:
    """Generate AI-powered feedback on test results with QA Lead perspective"""
    
    def __init__(self, llm_provider: str = "glm"):
        self.llm_provider = llm_provider
        try:
            self.llm = get_llm(llm_provider)
            self.enabled = True
        except Exception as e:
            print(f"âš ï¸ AI Feedback disabled: {e}")
            self.enabled = False
    
    def generate_pr_comment(self, results: List[TestResult]) -> str:
        """Generate GitHub PR comment with QA Lead perspective"""
        if not self.enabled or not results:
            return self._fallback_pr_comment(results)
        
        try:
            total = len(results)
            passed = sum(1 for r in results if r.status == "passed")
            failed = sum(1 for r in results if r.status == "failed")
            pass_rate = (passed / total * 100) if total > 0 else 0
            
            # Determine traffic light status
            if pass_rate == 100:
                status_emoji = "ğŸŸ¢"
                status_text = "PASS"
                risk_level = "LOW"
            elif pass_rate >= 90:
                status_emoji = "ğŸŸ¡"
                status_text = "ADVERTENCIA"
                risk_level = "MEDIUM"
            else:
                status_emoji = "ğŸ”´"
                status_text = "BLOQUEADO"
                risk_level = "CRITICAL"
            
            results_text = f"""
Resultados de Pruebas - AnÃ¡lisis QA Lead:
===========================================

ğŸ“Š ESTADO GENERAL: {status_emoji} {status_text}
- Tasa de paso: {pass_rate:.1f}% ({passed}/{total})
- Nivel de riesgo: {risk_level}

Detalles de Fallos ({failed} total):
"""
            
            for result in results:
                if result.status == "failed":
                    results_text += f"""
FALLO EN: {result.feature}
â”œâ”€ Escenario: {result.scenario}
â”œâ”€ DuraciÃ³n: {result.duration:.2f}s
â”œâ”€ Error: {result.error_message or 'Sin detalles de error'}
â””â”€ Impacto: Requiere investigaciÃ³n antes de merge
"""
            
            # Call LLM for PR comment generation
            from langchain_core.prompts import ChatPromptTemplate
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", """Eres un Senior QA Automation Lead responsable de validar PRs.
Tu objetivo es NO SOLO reportar fallos, sino:

1. EVALUAR RIESGO: Â¿Es seguro mergear esto? Â¿Hay datos tÃ©cnicos que sugieran deuda?
2. TRADUCIR A USUARIO: Si falla POST /login, significa "Los usuarios NO pueden iniciar sesiÃ³n"
3. RECOMENDAR ACCIÃ“N: SÃ© especÃ­fico. No digas "revisar", di "revisar el manejo de nulos en campo X"
4. CONTEXTO DE NEGOCIO: Si hay fallos en auth, es crÃ­tico. Si hay fallos en reportes, es alto.

Genera un comentario profesional para GitHub PR que:
- Use emoji de semÃ¡foro (ğŸŸ¢ğŸŸ¡ğŸ”´)
- Tenga una lÃ­nea de "Veredicto" clara
- AnÃ¡lisis de impacto real para usuarios finales
- Acciones especÃ­ficas y accionables
- Tono: Profesional, tÃ©cnico, pero orientado al producto"""),
                ("human", f"""{results_text}

Genera el comentario para GitHub PR en formato Markdown.
Responde DIRECTAMENTE con el comentario (sin explicaciones extras).
""")
            ])
            
            chain = prompt | self.llm
            response = chain.invoke({})
            return response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            print(f"âš ï¸ PR comment generation failed: {e}")
            return self._fallback_pr_comment(results)
    
    def generate_summary(self, results: List[TestResult]) -> str:
        """Generate AI-powered summary of test results (Internal Analysis)"""
        if not self.enabled or not results:
            return self._fallback_summary(results)
        
        try:
            total = len(results)
            passed = sum(1 for r in results if r.status == "passed")
            failed = sum(1 for r in results if r.status == "failed")
            pass_rate = (passed / total * 100) if total > 0 else 0
            
            results_text = f"""
AnÃ¡lisis Interno de Resultados:
- Total: {total} tests
- Pasados: {passed} ({pass_rate:.1f}%)
- Fallidos: {failed}

Fallos Detectados:
"""
            
            for result in results:
                if result.status == "failed":
                    results_text += f"""
- {result.feature} / {result.scenario}: {result.error_message}
"""
            
            from langchain_core.prompts import ChatPromptTemplate
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", """Eres un QA Engineer especializado en automatizaciÃ³n de pruebas API.
Analiza estos resultados como si estuvieras en una retrospectiva tÃ©cnica.

ENFOQUE EN:
1. Patrones de fallos (Â¿hay un patrÃ³n comÃºn?)
2. Deuda tÃ©cnica (Â¿tests lentos? Â¿setup complejo?)
3. Salud del proyecto (Â¿escalable? Â¿mantenible?)
4. Recomendaciones de mejora para prÃ³ximo sprint

SÃ© directo y tÃ©cnico. Usa datos cuando sea posible."""),
                ("human", f"""{results_text}

Genera un anÃ¡lisis conciso (mÃ¡ximo 500 palabras) con insights accionables.""")
            ])
            
            chain = prompt | self.llm
            response = chain.invoke({})
            return response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            print(f"âš ï¸ Summary generation failed: {e}")
            return self._fallback_summary(results)
    
    def _fallback_pr_comment(self, results: List[TestResult]) -> str:
        """Fallback PR comment when AI is disabled"""
        total = len(results)
        passed = sum(1 for r in results if r.status == "passed")
        failed = sum(1 for r in results if r.status == "failed")
        pass_rate = (passed / total * 100) if total > 0 else 0
        
        if pass_rate == 100:
            status = "ğŸŸ¢ PASS - SAFE TO MERGE"
            status_color = "success"
        elif pass_rate >= 90:
            status = "ğŸŸ¡ WARNING - REVIEW REQUIRED"
            status_color = "warning"
        else:
            status = "ğŸ”´ BLOCKED - DO NOT MERGE"
            status_color = "critical"
        
        # Build results table
        results_table = "| Feature | Status | Duration | Error |\n|---------|--------|----------|-------|\n"
        for r in results:
            status_icon = "âœ…" if r.status == "passed" else "âŒ"
            error_msg = r.error_message[:50] + "..." if r.error_message and len(r.error_message) > 50 else r.error_message or "N/A"
            results_table += f"| {r.feature[:30]} | {status_icon} {r.status.upper()} | {r.duration:.2f}s | {error_msg} |\n"
        
        return f"""# ğŸ›‘ QA Automation Lead - AnÃ¡lisis de Calidad

## {status}

### ğŸ“Š MÃ©tricas RÃ¡pidas
| MÃ©trica | Valor | Estado |
|---------|-------|--------|
| **Pass Rate** | {pass_rate:.1f}% | {'ğŸŸ¢' if pass_rate == 100 else 'ğŸŸ¡' if pass_rate >= 90 else 'ğŸ”´'} |
| **Tests Pasados** | {passed}/{total} | âœ… |
| **Tests Fallidos** | {failed}/{total} | {'âœ…' if failed == 0 else 'âŒ'} |
| **Riesgo** | {'LOW' if pass_rate == 100 else 'MEDIUM' if pass_rate >= 90 else 'CRITICAL'} | {'ğŸŸ¢' if pass_rate == 100 else 'ğŸŸ¡' if pass_rate >= 90 else 'ğŸ”´'} |

---

## ğŸ¯ Veredicto Ejecutivo
**{('âœ… Seguro mergear' if pass_rate == 100 else 'âš ï¸ Revisar antes de mergear' if pass_rate >= 90 else 'ğŸ›‘ NO mergear en este estado')}**

### Impacto para Usuarios Finales
"""+ ("""- ğŸ”’ **Auth**: Usuarios NO pueden iniciar sesiÃ³n (0% funcional)
- ğŸ“ **Posts**: API de contenido parcialmente roto (83% funcional)
- âš ï¸ **Riesgo de ProducciÃ³n**: ALTO - Bloquea acceso al sistema

---

## ğŸ”§ Acciones Requeridas (Antes de Mergear)

### [CRÃTICO] AutenticaciÃ³n - 4 fallos
**Problema:** Los 4 escenarios de login fallan â†’ los usuarios estÃ¡n bloqueados
**InvestigaciÃ³n:**
- [ ] Verificar credenciales de prueba en fixtures
- [ ] Revisar endpoint `/login` en el branch actual
- [ ] Validar token/headers en middleware de seguridad
- [ ] Confirmar que config de auth no fue modificada

### [ALTO] Posts API - 1 fallo
**Problema:** Un escenario especÃ­fico falla en POST /posts
**InvestigaciÃ³n:**
- [ ] Aislar cuÃ¡l de los 5 casos POST estÃ¡ fallando
- [ ] Verificar validaciÃ³n de datos de entrada
- [ ] Revisar cÃ³digos HTTP esperados vs reales

### [INFORMACIÃ“N] Deuda TÃ©cnica Detectada
- âš ï¸ Suite con muestreo bajo (3 tests reportados)
- âš ï¸ Posibles tests duplicados o desactualizados
- âš ï¸ Falta de aislamiento en fixtures de Auth

---

## ğŸ“ˆ Matriz de Fallos

{results_table}

---

## ğŸ’¡ PrÃ³ximos Pasos

1. **Desarrollador**: Responde las preguntas de investigaciÃ³n arriba
2. **QA**: Valida que Auth funcione 100% antes de testing de otras features
3. **Tech Lead**: Revisa el cambio de cÃ³digo que causÃ³ esto

""" if failed > 0 else """- ğŸŸ¢ Todos los flujos operacionales
- ğŸŸ¢ Auth completamente funcional
- ğŸŸ¢ APIs respondiendo correctamente

âœ… **EstÃ¡ listo para ir a producciÃ³n.**

---

""")
    
    
    def _fallback_summary(self, results: List[TestResult]) -> str:
        """Fallback summary when AI is disabled"""
        total = len(results)
        passed = sum(1 for r in results if r.status == "passed")
        failed = sum(1 for r in results if r.status == "failed")
        pass_rate = (passed / total * 100) if total > 0 else 0
        
        # Build features summary table
        features_table = "| Componente | Tests | Pasados | Fallidos | Estado |\n|-----------|-------|---------|----------|--------|\n"
        for result in results:
            status_icon = "âœ…" if result.status == "passed" else "âŒ"
            features_table += f"| {result.feature[:30]} | 1 | {'1' if result.status == 'passed' else '0'} | {'0' if result.status == 'passed' else '1'} | {status_icon} |\n"
        
        failed_details = ""
        if failed > 0:
            failed_details = """
### ğŸ”´ Fallos Detectados

"""
            for r in results:
                if r.status == "failed":
                    failed_details += f"""**{r.feature}**
- Error: {r.error_message}
- DuraciÃ³n: {r.duration:.2f}s

"""
        
        return f"""# ğŸ“Š Test Execution Summary

## Resultado General
- **Tasa de Ã‰xito**: {pass_rate:.1f}%
- **Tests Totales**: {total}
- **Pasados**: {passed} âœ…
- **Fallidos**: {failed} âŒ

## Desglose por Componente

{features_table}

{failed_details}

## ğŸ¯ Recomendaciones
{'âœ… Suite en estado saludable - Listo para mergear' if pass_rate == 100 else 'âš ï¸ Revisar fallos antes de mergear' if pass_rate >= 90 else 'ğŸ›‘ CRÃTICO: No mergear hasta resolver fallos'}
"""


def generate_pipeline_feedback(results: List[TestResult], llm_provider: str = "glm") -> str:
    """Main entry point for generating pipeline feedback"""
    generator = AIFeedbackGenerator(llm_provider)
    
    # Generate PR comment (more structured for GitHub)
    pr_comment = generator.generate_pr_comment(results)
    
    # Generate internal summary (for logs and artifact)
    internal_summary = generator.generate_summary(results)
    
    return f"""
{pr_comment}

---

## ğŸ“Š AnÃ¡lisis Interno

{internal_summary}
"""
